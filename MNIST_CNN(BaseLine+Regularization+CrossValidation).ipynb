{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598663560409",
   "display_name": "Python 3.6.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DACON 컴퓨터 비전 학습 경진대회\n",
    "### 2020.08.03 ~ 2020.09.14 17:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "#### make data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA(Exploratory Data Analysis, 탐색적 데이터 분석)\n",
    "#### visualize data and find the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (http://matplotlib.org/) -->\r\n<svg height=\"198.378068pt\" version=\"1.1\" viewBox=\"0 0 380.770653 198.378068\" width=\"380.770653pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 198.378068 \r\nL 380.770653 198.378068 \r\nL 380.770653 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 174.499943 \r\nL 179.106818 174.499943 \r\nL 179.106818 22.318125 \r\nL 26.925 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p6c659eef81)\">\r\n    <image height=\"153\" id=\"image37b9424663\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-21.499943\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m2ed1863e74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.642532\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-30\"/>\r\n      </defs>\r\n      <g transform=\"translate(26.461282 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.993182\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-31\"/>\r\n      </defs>\r\n      <g transform=\"translate(77.630682 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.343831\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-32\"/>\r\n      </defs>\r\n      <g transform=\"translate(131.981331 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_4\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m1055f6108c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"25.035657\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 28.834876)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"52.210982\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-35\"/>\r\n      </defs>\r\n      <g transform=\"translate(13.5625 56.010201)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"79.386307\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 83.185526)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"106.561631\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 110.36085)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"133.736956\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 137.536175)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1055f6108c\" y=\"160.912281\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 164.7115)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 174.499943 \r\nL 26.925 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 179.106818 174.499943 \r\nL 179.106818 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 174.499943 \r\nL 179.106818 174.499943 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 22.318125 \r\nL 179.106818 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path d=\"M 209.543182 174.499943 \r\nL 361.725 174.499943 \r\nL 361.725 22.318125 \r\nL 209.543182 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pb73c0b0a31)\">\r\n    <image height=\"153\" id=\"image8c5b7aa848\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAJkAAACZCAYAAAA8XJi6AAAABHNCSVQICAgIfAhkiAAABCBJREFUeJzt3c+LVWUYwPH3zs3mqjniTIbTLwrxipIVDJMhRJESBNHKRW1aJbVt1bI/I6VNK7cWhOAmWrVIk3GYkMaSYSobDUe0ZMaZ0ekPeJ67mOZ87znevp/lw8v4Cl9fzuE457SOtY6vFwk0VPcGNPiMTDgjE87IhDMy4YxMOCMTzsiEMzLhjEw4IxPOyIQzMuGMTDgjE87IhDMy4YxMOCMTzsiEMzLhHql7A4Ns9ovJdL5/77Uwu3pjLF37/HvTle6pDp5kwhmZcEYmnJEJ54X/Bl35ciKdj++5FWafPns2Xfvm9tk43Jv/ed/MHAqzcy+M9N5gA3mSCWdkwhmZcEYmnJEJ1/IleP237/xwmL2762K69nDnTph9dv21dO3libXNbQziSSackQlnZMIZmXA+VqrBlcl7YXbux/j4qJRSjnS+D7Or/zze4ycvbGZbGE8y4YxMOCMTzsiEMzLhGnF3ee3MwTA7sPt6uvb2va1xePT3qrfUd2dmXk7nh3f8GmZD5eF6EuhJJpyRCWdkwhmZcI34/2RHLq2E2TsjU+na39ZGw+yT795P13ZPnN/cxhpg/4UtYTa9+FS6dvitOXg3/40nmXBGJpyRCWdkwhmZcI14rJTdSU4MP5qubZebcVj7/TFn6ubTYbZwa0e6dvXkK2HW/fiHyve0UZ5kwhmZcEYmnJEJ14gL/2/vHgiz3e1L6drRdjIcGuAr/0S7nf99V3vM6+ZJJpyRCWdkwhmZcEYmXCPuLj+/+HqYff3ES+nao+M/h1n3wwuV76nfZpNHQqWU8vZo/LbS9PqT6do//o4v12sCTzLhjEw4IxPOyIRrxIX/vg/im597fZD0q+UXw2xPuVz5nvqux6OxicfmwmxxZVu69s8tO6vcUWU8yYQzMuGMTDgjE87IhGvE3WVmEN5jsRGtzv10/sa2X8JsfmUsXTs1nL8jo26eZMIZmXBGJpyRCdfYC///m/Wl7Newct1O/g2lke3LVW2nUp5kwhmZcEYmnJEJ54V/Q3Q/yp9wLM/FG4LJzny69rmdi2F2e3PbqoQnmXBGJpyRCWdkwhmZcN5dNsTsqfy3s/66H19TML8avy9VSikzC+Nh9kz2tvA+8yQTzsiEMzLhjEw4L/wbYuvYUjq/86ATZj8txU/hlFLK8t38U0F18yQTzsiEMzLhjEw4IxPOu8uGWFvL/72fvvFqmD1Yb+U/pNe8Zp5kwhmZcEYmnJEJ1zrWOt7ML3FqYHiSCWdkwhmZcEYmnJEJZ2TCGZlwRiackQlnZMIZmXBGJpyRCWdkwhmZcEYmnJEJZ2TCGZlwRiackQlnZMIZmXBGJpyRCWdkwhmZcEYmnJEJZ2TCGZlwRiackQlnZMIZmXBGJpyRCWdkwhmZcEYmnJEJZ2TCGZlw/wLwTIl7GeWUogAAAABJRU5ErkJggg==\" y=\"-21.499943\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.260714\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(209.079464 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.611364\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(260.248864 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"320.962013\" xlink:href=\"#m2ed1863e74\" y=\"174.499943\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(314.599513 189.098381)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"25.035657\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 28.834876)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"52.210982\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(196.180682 56.010201)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"79.386307\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(189.818182 83.185526)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"106.561631\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(189.818182 110.36085)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"133.736956\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(189.818182 137.536175)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m1055f6108c\" y=\"160.912281\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(189.818182 164.7115)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 209.543182 174.499943 \r\nL 209.543182 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 361.725 174.499943 \r\nL 361.725 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 209.543182 174.499943 \r\nL 361.725 174.499943 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 209.543182 22.318125 \r\nL 361.725 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_19\">\r\n    <!-- Index: 319, Digit: 0, Letter: D -->\r\n    <defs>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n     <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-6e\"/>\r\n     <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-64\"/>\r\n     <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n     <path d=\"M 54.890625 54.6875 \r\nL 35.109375 28.078125 \r\nL 55.90625 0 \r\nL 45.3125 0 \r\nL 29.390625 21.484375 \r\nL 13.484375 0 \r\nL 2.875 0 \r\nL 24.125 28.609375 \r\nL 4.6875 54.6875 \r\nL 15.28125 54.6875 \r\nL 29.78125 35.203125 \r\nL 44.28125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n     <path d=\"M 11.71875 12.40625 \r\nL 22.015625 12.40625 \r\nL 22.015625 0 \r\nL 11.71875 0 \r\nz\r\nM 11.71875 51.703125 \r\nL 22.015625 51.703125 \r\nL 22.015625 39.3125 \r\nL 11.71875 39.3125 \r\nz\r\n\" id=\"DejaVuSans-3a\"/>\r\n     <path id=\"DejaVuSans-20\"/>\r\n     <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-33\"/>\r\n     <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-39\"/>\r\n     <path d=\"M 11.71875 12.40625 \r\nL 22.015625 12.40625 \r\nL 22.015625 4 \r\nL 14.015625 -11.625 \r\nL 7.71875 -11.625 \r\nL 11.71875 4 \r\nz\r\n\" id=\"DejaVuSans-2c\"/>\r\n     <path d=\"M 19.671875 64.796875 \r\nL 19.671875 8.109375 \r\nL 31.59375 8.109375 \r\nQ 46.6875 8.109375 53.6875 14.9375 \r\nQ 60.6875 21.78125 60.6875 36.53125 \r\nQ 60.6875 51.171875 53.6875 57.984375 \r\nQ 46.6875 64.796875 31.59375 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 30.078125 72.90625 \r\nQ 51.265625 72.90625 61.171875 64.09375 \r\nQ 71.09375 55.28125 71.09375 36.53125 \r\nQ 71.09375 17.671875 61.125 8.828125 \r\nQ 51.171875 0 30.078125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-44\"/>\r\n     <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n     <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n     <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-74\"/>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-4c\"/>\r\n     <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-72\"/>\r\n    </defs>\r\n    <g transform=\"translate(197.697528 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-49\"/>\r\n     <use x=\"29.492188\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"92.871094\" xlink:href=\"#DejaVuSans-64\"/>\r\n     <use x=\"156.347656\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"217.855469\" xlink:href=\"#DejaVuSans-78\"/>\r\n     <use x=\"277.035156\" xlink:href=\"#DejaVuSans-3a\"/>\r\n     <use x=\"310.726562\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"342.513672\" xlink:href=\"#DejaVuSans-33\"/>\r\n     <use x=\"406.136719\" xlink:href=\"#DejaVuSans-31\"/>\r\n     <use x=\"469.759766\" xlink:href=\"#DejaVuSans-39\"/>\r\n     <use x=\"533.382812\" xlink:href=\"#DejaVuSans-2c\"/>\r\n     <use x=\"565.169922\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"596.957031\" xlink:href=\"#DejaVuSans-44\"/>\r\n     <use x=\"673.958984\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"701.742188\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"765.21875\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"793.001953\" xlink:href=\"#DejaVuSans-74\"/>\r\n     <use x=\"832.210938\" xlink:href=\"#DejaVuSans-3a\"/>\r\n     <use x=\"865.902344\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"897.689453\" xlink:href=\"#DejaVuSans-30\"/>\r\n     <use x=\"961.3125\" xlink:href=\"#DejaVuSans-2c\"/>\r\n     <use x=\"993.099609\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"1024.886719\" xlink:href=\"#DejaVuSans-4c\"/>\r\n     <use x=\"1080.583984\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"1142.107422\" xlink:href=\"#DejaVuSans-74\"/>\r\n     <use x=\"1181.316406\" xlink:href=\"#DejaVuSans-74\"/>\r\n     <use x=\"1220.525391\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"1282.048828\" xlink:href=\"#DejaVuSans-72\"/>\r\n     <use x=\"1323.146484\" xlink:href=\"#DejaVuSans-3a\"/>\r\n     <use x=\"1356.837891\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"1388.625\" xlink:href=\"#DejaVuSans-44\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p6c659eef81\">\r\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"26.925\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pb73c0b0a31\">\r\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"209.543182\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  152 184 183 143   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  156 220 198 144   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  136 225 214 156   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0 233 235 183   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  136 236 215 166   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  145 236 201 154   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0 138 161   0   0   0   0   0   0   0   0   0\n  137 212 184 146   0   0   0   0   0   0]\n [  0   0   0   0   0   0 145 169 201   0   0   0   0   0   0   0   0   0\n  135 192 169 141   0   0   0   0   0   0]\n [  0   0   0   0   0   0 206 238 238 139   0   0   0   0   0   0   0   0\n    0 170 155 138   0   0   0   0   0   0]\n [  0   0   0   0   0   0 230 250 231 137   0   0   0   0   0   0   0   0\n    0 170 152 135   0   0   0   0   0   0]\n [  0   0   0   0   0   0 202 230 219 138   0   0   0   0   0   0   0   0\n    0 194 171   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0 159 183 175   0   0   0   0   0   0   0   0   0\n  144 217 180   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n  196 245 179   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 193\n  223 244 195   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 143 168 210 235\n  235 207   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 176\n  152   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]]\n"
    }
   ],
   "source": [
    "idx = 319\n",
    "img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
    "digit = train.loc[idx, 'digit']\n",
    "letter = train.loc[idx, 'letter']\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "\n",
    "for n, i in enumerate(img):\n",
    "    for m, j in enumerate(i):\n",
    "        if img[n][m] < 10:\n",
    "            img[n][m] = img[n][m]*0.1\n",
    "            \n",
    "        if img[n][m] < 135:\n",
    "            img[n][m] = 0\n",
    "        \n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### add feature image to the second channel of data.(data becomes (-1, 28, 28, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2048, 26, 26, 1)\n"
    }
   ],
   "source": [
    "x = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x = x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x = np.delete(x, (0), axis=1)\n",
    "x = np.delete(x, (-1), axis=1)\n",
    "x = np.delete(x, (0), axis=2)\n",
    "x = np.delete(x, (-1), axis=2)\n",
    "\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c78a337b8d2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This cell add feature channel(only digit pixels data) to the x_train. (x_train becomes (-1,28,28,2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_preprocessing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# This cell add feature channel(only digit pixels data) to the x_train. (x_train becomes (-1,28,28,2))\n",
    "\n",
    "x_preprocessing = np.array(np.zeros(x_train.shape))\n",
    "\n",
    "for p, img in enumerate(x):\n",
    "    for q, i in enumerate(img):\n",
    "        for r, j in enumerate(i):\n",
    "            if img[q][r] < 135:\n",
    "                x_preprocessing[p][q][r] = 0\n",
    "                \n",
    "x = np.concatenate((x, x_preprocessing), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255\n",
    "\n",
    "y_data = train['digit']\n",
    "y = np.zeros((len(y_data), len(y_data.unique())))\n",
    "for i, digit in enumerate(y_data):\n",
    "    y[i, digit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2048, 26, 26, 1)\n(2048, 10)\n(409, 26, 26, 1)\n(409, 10)\n(1639, 26, 26, 1)\n(1639, 10)\n"
    }
   ],
   "source": [
    "x_val = x[-int(len(x)*0.2):]\n",
    "y_val = y[-int(len(y)*0.2):]\n",
    "x_train = x[:-int(len(x)*0.2)]\n",
    "y_train = y[:-int(len(y)*0.2)]\n",
    "\n",
    "print(str(x.shape))\n",
    "print(str(y.shape))\n",
    "print(str(x_val.shape))\n",
    "print(str(y_val.shape))\n",
    "print(str(x_train.shape))\n",
    "print(str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(x_train):\n",
    "    inputs = tf.keras.layers.Input(x_train.shape[1:])\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(128,kernel_size=5, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', kernel_initializer= 'glorot_normal')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_accuracy:.4f}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy', verbose=1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 80:\n",
    "    return lr\n",
    "  elif epoch >150:\n",
    "      return lr *0.01\n",
    "  else:\n",
    "    return lr*0.85\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[   0    1    2 ... 2045 2046 2047]\n[   0    2    3 ... 2045 2046 2047]\n[   0    1    2 ... 2043 2046 2047]\n[   1    2    3 ... 2043 2044 2045]\n[   0    1    3 ... 2045 2046 2047]\n"
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train_range, test_range in kfold.split(x, y):\n",
    "    print(train_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=======>.] - ETA: 0s - loss: 1.3900 - accuracy: 0.9281\nEpoch 00056: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3955 - accuracy: 0.9256 - val_loss: 2.1380 - val_accuracy: 0.7384\nEpoch 57/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.7779 - accuracy: 0.9154\nEpoch 00057: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.7770 - accuracy: 0.9152 - val_loss: 2.8327 - val_accuracy: 0.6650\nEpoch 58/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.6449 - accuracy: 0.9210\nEpoch 00058: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.6434 - accuracy: 0.9213 - val_loss: 2.0728 - val_accuracy: 0.7775\nEpoch 59/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3696 - accuracy: 0.9320\nEpoch 00059: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3688 - accuracy: 0.9323 - val_loss: 2.0787 - val_accuracy: 0.7579\nEpoch 60/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.2762 - accuracy: 0.9344\nEpoch 00060: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2761 - accuracy: 0.9347 - val_loss: 1.8734 - val_accuracy: 0.7726\nEpoch 61/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3650 - accuracy: 0.9308\nEpoch 00061: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3644 - accuracy: 0.9311 - val_loss: 2.2355 - val_accuracy: 0.7139\nEpoch 62/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.2668 - accuracy: 0.9363\nEpoch 00062: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2665 - accuracy: 0.9359 - val_loss: 1.7059 - val_accuracy: 0.7751\nEpoch 63/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.4883 - accuracy: 0.9216\nEpoch 00063: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.4889 - accuracy: 0.9207 - val_loss: 2.1897 - val_accuracy: 0.7628\nEpoch 64/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.6125 - accuracy: 0.9112\nEpoch 00064: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.6110 - accuracy: 0.9109 - val_loss: 2.3347 - val_accuracy: 0.7751\nEpoch 65/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.4044 - accuracy: 0.9357\nEpoch 00065: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.4078 - accuracy: 0.9341 - val_loss: 1.9995 - val_accuracy: 0.7873\nEpoch 66/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.8760 - accuracy: 0.9106\nEpoch 00066: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.8690 - accuracy: 0.9115 - val_loss: 2.3895 - val_accuracy: 0.7213\nEpoch 67/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.2207 - accuracy: 0.9504\nEpoch 00067: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2203 - accuracy: 0.9506 - val_loss: 1.8317 - val_accuracy: 0.7433\nEpoch 68/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.2120 - accuracy: 0.9375\nEpoch 00068: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2237 - accuracy: 0.9341 - val_loss: 2.1928 - val_accuracy: 0.6919\nEpoch 69/120\n1632/1639 [============================>.] - ETA: 0s - loss: 2.1166 - accuracy: 0.8928\nEpoch 00069: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 2.1151 - accuracy: 0.8926 - val_loss: 2.4744 - val_accuracy: 0.7995\nEpoch 70/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.9479\nEpoch 00070: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.5322 - accuracy: 0.9481 - val_loss: 1.8210 - val_accuracy: 0.7971\nEpoch 71/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.1492 - accuracy: 0.9583\nEpoch 00071: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.1504 - accuracy: 0.9579 - val_loss: 2.0964 - val_accuracy: 0.6895\nEpoch 72/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.4395 - accuracy: 0.9375\nEpoch 00072: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.4380 - accuracy: 0.9372 - val_loss: 2.1833 - val_accuracy: 0.7457\nEpoch 73/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3393 - accuracy: 0.9393\nEpoch 00073: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3390 - accuracy: 0.9396 - val_loss: 2.0511 - val_accuracy: 0.7482\nEpoch 74/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.2502 - accuracy: 0.9387\nEpoch 00074: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2498 - accuracy: 0.9390 - val_loss: 2.4713 - val_accuracy: 0.7042\nEpoch 75/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3170 - accuracy: 0.9375\nEpoch 00075: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3162 - accuracy: 0.9378 - val_loss: 2.0797 - val_accuracy: 0.7433\nEpoch 76/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.0733 - accuracy: 0.9644\nEpoch 00076: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.0753 - accuracy: 0.9622 - val_loss: 1.7014 - val_accuracy: 0.7237\nEpoch 77/120\n1600/1639 [============================>.] - ETA: 0s - loss: 1.8039 - accuracy: 0.9156\nEpoch 00077: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.8011 - accuracy: 0.9152 - val_loss: 2.4353 - val_accuracy: 0.7677\nEpoch 78/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.4777 - accuracy: 0.9375\nEpoch 00078: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.4778 - accuracy: 0.9372 - val_loss: 2.0920 - val_accuracy: 0.7726\nEpoch 79/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3706 - accuracy: 0.9412\nEpoch 00079: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3724 - accuracy: 0.9408 - val_loss: 1.8342 - val_accuracy: 0.8044\nEpoch 80/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3473 - accuracy: 0.9430\nEpoch 00080: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3476 - accuracy: 0.9420 - val_loss: 1.8111 - val_accuracy: 0.7848\nEpoch 81/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.3044 - accuracy: 0.9467\nEpoch 00081: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.3095 - accuracy: 0.9451 - val_loss: 1.9030 - val_accuracy: 0.7457\nEpoch 82/120\n1632/1639 [============================>.] - ETA: 0s - loss: 1.2609 - accuracy: 0.9577\nEpoch 00082: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 1.2598 - accuracy: 0.9579 - val_loss: 1.7374 - val_accuracy: 0.7824\nEpoch 83/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.8411 - accuracy: 0.9828\nEpoch 00083: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.8451 - accuracy: 0.9811 - val_loss: 1.3206 - val_accuracy: 0.7873\nEpoch 84/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.9948 - accuracy: 0.9675\nEpoch 00084: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.9916 - accuracy: 0.9677 - val_loss: 1.5074 - val_accuracy: 0.7555\nEpoch 85/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.9871\nEpoch 00085: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.6743 - accuracy: 0.9872 - val_loss: 1.1639 - val_accuracy: 0.7971\nEpoch 86/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.9988\nEpoch 00086: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.4537 - accuracy: 0.9988 - val_loss: 0.9573 - val_accuracy: 0.7995\nEpoch 87/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9982\nEpoch 00087: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3503 - accuracy: 0.9982 - val_loss: 0.9013 - val_accuracy: 0.8068\nEpoch 88/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.9951\nEpoch 00088: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3144 - accuracy: 0.9951 - val_loss: 0.9309 - val_accuracy: 0.7995\nEpoch 89/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.9951\nEpoch 00089: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2991 - accuracy: 0.9951 - val_loss: 0.8869 - val_accuracy: 0.8068\nEpoch 90/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9982\nEpoch 00090: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2654 - accuracy: 0.9982 - val_loss: 0.8171 - val_accuracy: 0.8020\nEpoch 91/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9994\nEpoch 00091: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2324 - accuracy: 0.9994 - val_loss: 0.7348 - val_accuracy: 0.8240\nEpoch 92/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9994\nEpoch 00092: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2033 - accuracy: 0.9994 - val_loss: 0.6871 - val_accuracy: 0.8240\nEpoch 93/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 1.0000\nEpoch 00093: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1833 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8362\nEpoch 94/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9945\nEpoch 00094: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2112 - accuracy: 0.9945 - val_loss: 0.7888 - val_accuracy: 0.8044\nEpoch 95/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.1999 - accuracy: 0.9969\nEpoch 00095: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2000 - accuracy: 0.9969 - val_loss: 0.7781 - val_accuracy: 0.8117\nEpoch 96/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9994\nEpoch 00096: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1859 - accuracy: 0.9994 - val_loss: 0.7636 - val_accuracy: 0.8020\nEpoch 97/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9994\nEpoch 00097: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1768 - accuracy: 0.9994 - val_loss: 0.7383 - val_accuracy: 0.8068\nEpoch 98/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 1.0000\nEpoch 00098: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1640 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8215\nEpoch 99/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 1.0000\nEpoch 00099: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1560 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8289\nEpoch 100/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 1.0000\nEpoch 00100: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1487 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8240\nEpoch 101/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 1.0000\nEpoch 00101: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8337\nEpoch 102/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 1.0000\nEpoch 00102: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1407 - accuracy: 0.9994 - val_loss: 0.6653 - val_accuracy: 0.8386\nEpoch 103/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 1.0000\nEpoch 00103: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1381 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8289\nEpoch 104/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 1.0000\nEpoch 00104: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1359 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8362\nEpoch 105/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 1.0000\nEpoch 00105: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1334 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8337\nEpoch 106/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 1.0000\nEpoch 00106: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8289\nEpoch 107/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 1.0000\nEpoch 00107: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1316 - accuracy: 0.9994 - val_loss: 0.6779 - val_accuracy: 0.8313\nEpoch 108/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 1.0000\nEpoch 00108: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8386\nEpoch 109/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 1.0000\nEpoch 00109: val_accuracy did not improve from 0.83902\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8386\nEpoch 110/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 1.0000\nEpoch 00110: val_accuracy improved from 0.83902 to 0.84108, saving model to ./model/110-0.8411-0.6818.hdf5\n1639/1639 [==============================] - 4s 2ms/sample - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8411\nEpoch 111/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 1.0000\nEpoch 00111: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8411\nEpoch 112/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 1.0000\nEpoch 00112: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1264 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8411\nEpoch 113/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 1.0000\nEpoch 00113: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8362\nEpoch 114/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 1.0000\nEpoch 00114: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8411\nEpoch 115/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 1.0000\nEpoch 00115: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8386\nEpoch 116/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 1.0000\nEpoch 00116: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1262 - accuracy: 0.9994 - val_loss: 0.6766 - val_accuracy: 0.8411\nEpoch 117/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 1.0000\nEpoch 00117: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1260 - accuracy: 0.9994 - val_loss: 0.6697 - val_accuracy: 0.8411\nEpoch 118/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 1.0000\nEpoch 00118: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8386\nEpoch 119/120\n1600/1639 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 1.0000\nEpoch 00119: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8386\nEpoch 120/120\n1632/1639 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 1.0000\nEpoch 00120: val_accuracy did not improve from 0.84108\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8386\nScore for fold 5: loss of 0.6718303282861313; accuracy of 83.86307954788208%\n------------------------------------------------------------------------\nScore per fold\n------------------------------------------------------------------------\n> Fold 1 - Loss: 0.7711730378430064 - Accuracy: 83.65853428840637%\n------------------------------------------------------------------------\n> Fold 2 - Loss: 0.7949970012757837 - Accuracy: 81.95121884346008%\n------------------------------------------------------------------------\n> Fold 3 - Loss: 0.7787069954523226 - Accuracy: 82.43902325630188%\n------------------------------------------------------------------------\n> Fold 4 - Loss: 0.8176049871374751 - Accuracy: 81.17359280586243%\n------------------------------------------------------------------------\n> Fold 5 - Loss: 0.6718303282861313 - Accuracy: 83.86307954788208%\n------------------------------------------------------------------------\nAverage scores for all folds:\n> Accuracy: 82.61708974838257 (+- 1.0193990848623942)\n> Loss: 0.7668624699989438\n------------------------------------------------------------------------\n"
    }
   ],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train_range, val_range in kfold.split(x, y):\n",
    "\n",
    "  # Define the model architecture\n",
    "  model = create_cnn_model(x[train_range])\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(\n",
    "      loss='categorical_crossentropy',\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  epochs=120\n",
    "  history = model.fit(x[train_range], y[train_range], validation_data= (x[val_range], y[val_range]), epochs=epochs, callbacks=[cb_checkpoint, lr_scheduler])\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model.evaluate(x[val_range], y[val_range], verbose=0)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "  acc_per_fold.append(scores[1] * 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.0591422905257395, 0.9608802]\n"
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(x_train):\n",
    "    inputs = tf.keras.layers.Input(x_train.shape[1:])\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(128,kernel_size=5, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01))(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', kernel_initializer= 'glorot_normal')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "    \n",
    "model = create_cnn_model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Input(x_train.shape[1:]),\n",
    "\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  layers.Dropout(0.25),\n",
    "\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01)),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01)),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  layers.Dropout(0.25),\n",
    "\n",
    "  layers.Flatten(),\n",
    "\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(1000, activation='relu', kernel_initializer='he_normal',kernel_regularizer =keras.regularizers.l2( l=0.01)),\n",
    "  \n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(num_classes, activation='softmax', kernel_initializer= 'glorot_normal')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_accuracy:.4f}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy', verbose=1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 80:\n",
    "    return lr\n",
    "  elif epoch >150:\n",
    "      return lr *0.01\n",
    "  else:\n",
    "    return lr*0.85     # lr 0.8이 최적의 값(0.001*0.8=0.0008)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "#### using variation of baseline model\n",
    "#### + add kernel_initializer='he_normal'\n",
    "#### + add kernel_regularizer =keras.regularizers.l2( l=0.01)\n",
    "#### + add kernel_initializer= 'glorot_normal'\n",
    "#### .\n",
    "#### first cell is 'add type' model\n",
    "#### second cell is 'sequential type' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1639 samples, validate on 409 samples\nEpoch 1/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.9773\nEpoch 00001: val_accuracy did not improve from 0.85086\n1639/1639 [==============================] - 4s 2ms/sample - loss: 0.4976 - accuracy: 0.9774 - val_loss: 0.8834 - val_accuracy: 0.8509\nEpoch 2/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.4740 - accuracy: 0.9822\nEpoch 00002: val_accuracy improved from 0.85086 to 0.85819, saving model to ./model/02-0.8582-0.8631.hdf5\n1639/1639 [==============================] - 4s 2ms/sample - loss: 0.4739 - accuracy: 0.9823 - val_loss: 0.8631 - val_accuracy: 0.8582\nEpoch 3/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.4305 - accuracy: 0.9908\nEpoch 00003: val_accuracy did not improve from 0.85819\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.4305 - accuracy: 0.9908 - val_loss: 0.7945 - val_accuracy: 0.8582\nEpoch 4/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.3994 - accuracy: 0.9944\nEpoch 00004: val_accuracy did not improve from 0.85819\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3991 - accuracy: 0.9945 - val_loss: 0.8118 - val_accuracy: 0.8582\nEpoch 5/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.9939\nEpoch 00005: val_accuracy did not improve from 0.85819\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3827 - accuracy: 0.9939 - val_loss: 0.7861 - val_accuracy: 0.8509\nEpoch 6/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.9933\nEpoch 00006: val_accuracy improved from 0.85819 to 0.86797, saving model to ./model/06-0.8680-0.7251.hdf5\n1639/1639 [==============================] - 3s 2ms/sample - loss: 0.3564 - accuracy: 0.9933 - val_loss: 0.7251 - val_accuracy: 0.8680\nEpoch 7/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.3346 - accuracy: 0.9969\nEpoch 00007: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3368 - accuracy: 0.9957 - val_loss: 0.7535 - val_accuracy: 0.8411\nEpoch 8/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.9914\nEpoch 00008: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3477 - accuracy: 0.9915 - val_loss: 0.7543 - val_accuracy: 0.8557\nEpoch 9/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.9937\nEpoch 00009: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3382 - accuracy: 0.9933 - val_loss: 0.7454 - val_accuracy: 0.8680\nEpoch 10/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3521 - accuracy: 0.9896\nEpoch 00010: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3519 - accuracy: 0.9896 - val_loss: 0.8020 - val_accuracy: 0.8337\nEpoch 11/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.9975\nEpoch 00011: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3269 - accuracy: 0.9976 - val_loss: 0.7519 - val_accuracy: 0.8533\nEpoch 12/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9914\nEpoch 00012: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3229 - accuracy: 0.9915 - val_loss: 0.8150 - val_accuracy: 0.8411\nEpoch 13/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3086 - accuracy: 0.9957\nEpoch 00013: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3087 - accuracy: 0.9957 - val_loss: 0.7113 - val_accuracy: 0.8655\nEpoch 14/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.9963\nEpoch 00014: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2959 - accuracy: 0.9951 - val_loss: 0.7039 - val_accuracy: 0.8509\nEpoch 15/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9871\nEpoch 00015: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3426 - accuracy: 0.9860 - val_loss: 0.8263 - val_accuracy: 0.8313\nEpoch 16/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.9926\nEpoch 00016: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3658 - accuracy: 0.9927 - val_loss: 0.9035 - val_accuracy: 0.8264\nEpoch 17/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9962\nEpoch 00017: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3338 - accuracy: 0.9957 - val_loss: 0.7928 - val_accuracy: 0.8680\nEpoch 18/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9963\nEpoch 00018: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3146 - accuracy: 0.9963 - val_loss: 0.8455 - val_accuracy: 0.8460\nEpoch 19/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.9957\nEpoch 00019: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2979 - accuracy: 0.9951 - val_loss: 0.7567 - val_accuracy: 0.8655\nEpoch 20/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.9926\nEpoch 00020: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3104 - accuracy: 0.9927 - val_loss: 0.7273 - val_accuracy: 0.8655\nEpoch 21/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.9951\nEpoch 00021: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3065 - accuracy: 0.9945 - val_loss: 0.7598 - val_accuracy: 0.8655\nEpoch 22/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.9957\nEpoch 00022: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3005 - accuracy: 0.9957 - val_loss: 0.7846 - val_accuracy: 0.8484\nEpoch 23/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9981\nEpoch 00023: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2681 - accuracy: 0.9982 - val_loss: 0.7360 - val_accuracy: 0.8509\nEpoch 24/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9962\nEpoch 00024: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2640 - accuracy: 0.9963 - val_loss: 0.7605 - val_accuracy: 0.8435\nEpoch 25/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9969\nEpoch 00025: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2474 - accuracy: 0.9969 - val_loss: 0.6989 - val_accuracy: 0.8582\nEpoch 26/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9988\nEpoch 00026: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2331 - accuracy: 0.9988 - val_loss: 0.7085 - val_accuracy: 0.8582\nEpoch 27/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9994\nEpoch 00027: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2193 - accuracy: 0.9994 - val_loss: 0.6832 - val_accuracy: 0.8484\nEpoch 28/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9914\nEpoch 00028: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2383 - accuracy: 0.9915 - val_loss: 0.8148 - val_accuracy: 0.8337\nEpoch 29/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9963\nEpoch 00029: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2356 - accuracy: 0.9963 - val_loss: 0.7528 - val_accuracy: 0.8435\nEpoch 30/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9987\nEpoch 00030: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2181 - accuracy: 0.9988 - val_loss: 0.6963 - val_accuracy: 0.8435\nEpoch 31/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9939\nEpoch 00031: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2136 - accuracy: 0.9939 - val_loss: 0.6615 - val_accuracy: 0.8411\nEpoch 32/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9951\nEpoch 00032: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2139 - accuracy: 0.9951 - val_loss: 0.6696 - val_accuracy: 0.8435\nEpoch 33/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9963\nEpoch 00033: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2122 - accuracy: 0.9957 - val_loss: 0.7214 - val_accuracy: 0.8411\nEpoch 34/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9871\nEpoch 00034: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2571 - accuracy: 0.9872 - val_loss: 0.8705 - val_accuracy: 0.8142\nEpoch 35/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.9875\nEpoch 00035: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2809 - accuracy: 0.9878 - val_loss: 0.7952 - val_accuracy: 0.8533\nEpoch 36/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.9804\nEpoch 00036: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3019 - accuracy: 0.9786 - val_loss: 0.8322 - val_accuracy: 0.8460\nEpoch 37/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.9847\nEpoch 00037: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3139 - accuracy: 0.9841 - val_loss: 0.8236 - val_accuracy: 0.8362\nEpoch 38/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.3150 - accuracy: 0.9914\nEpoch 00038: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3148 - accuracy: 0.9915 - val_loss: 0.7997 - val_accuracy: 0.8411\nEpoch 39/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.9931\nEpoch 00039: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2866 - accuracy: 0.9933 - val_loss: 0.7110 - val_accuracy: 0.8655\nEpoch 40/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9975\nEpoch 00040: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2634 - accuracy: 0.9976 - val_loss: 0.6894 - val_accuracy: 0.8582\nEpoch 41/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9969\nEpoch 00041: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2424 - accuracy: 0.9963 - val_loss: 0.6755 - val_accuracy: 0.8557\nEpoch 42/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9969\nEpoch 00042: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2478 - accuracy: 0.9969 - val_loss: 0.7569 - val_accuracy: 0.8533\nEpoch 43/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9963\nEpoch 00043: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2433 - accuracy: 0.9963 - val_loss: 0.7434 - val_accuracy: 0.8362\nEpoch 44/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.9969\nEpoch 00044: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2325 - accuracy: 0.9969 - val_loss: 0.6751 - val_accuracy: 0.8509\nEpoch 45/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9988\nEpoch 00045: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2130 - accuracy: 0.9988 - val_loss: 0.6894 - val_accuracy: 0.8484\nEpoch 46/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.9969\nEpoch 00046: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2079 - accuracy: 0.9963 - val_loss: 0.7241 - val_accuracy: 0.8386\nEpoch 47/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9933\nEpoch 00047: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2335 - accuracy: 0.9933 - val_loss: 0.7538 - val_accuracy: 0.8557\nEpoch 48/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9975\nEpoch 00048: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2301 - accuracy: 0.9969 - val_loss: 0.6998 - val_accuracy: 0.8655\nEpoch 49/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.9908\nEpoch 00049: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2492 - accuracy: 0.9908 - val_loss: 0.7524 - val_accuracy: 0.8509\nEpoch 50/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9914\nEpoch 00050: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2442 - accuracy: 0.9908 - val_loss: 0.7410 - val_accuracy: 0.8460\nEpoch 51/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9875\nEpoch 00051: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2778 - accuracy: 0.9872 - val_loss: 0.7927 - val_accuracy: 0.8386\nEpoch 52/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9933\nEpoch 00052: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2654 - accuracy: 0.9927 - val_loss: 0.7328 - val_accuracy: 0.8435\nEpoch 53/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9926\nEpoch 00053: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2706 - accuracy: 0.9927 - val_loss: 0.8084 - val_accuracy: 0.8411\nEpoch 54/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9951\nEpoch 00054: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2561 - accuracy: 0.9951 - val_loss: 0.8065 - val_accuracy: 0.8362\nEpoch 55/60\n1600/1639 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9931\nEpoch 00055: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2473 - accuracy: 0.9933 - val_loss: 0.7135 - val_accuracy: 0.8533\nEpoch 56/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9951\nEpoch 00056: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2377 - accuracy: 0.9951 - val_loss: 0.8307 - val_accuracy: 0.8362\nEpoch 57/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9969\nEpoch 00057: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2201 - accuracy: 0.9963 - val_loss: 0.7095 - val_accuracy: 0.8509\nEpoch 58/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2299 - accuracy: 0.9963\nEpoch 00058: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2307 - accuracy: 0.9957 - val_loss: 0.8012 - val_accuracy: 0.8337\nEpoch 59/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9945\nEpoch 00059: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2477 - accuracy: 0.9945 - val_loss: 0.8221 - val_accuracy: 0.8264\nEpoch 60/60\n1632/1639 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9969\nEpoch 00060: val_accuracy did not improve from 0.86797\n1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2347 - accuracy: 0.9969 - val_loss: 0.8049 - val_accuracy: 0.8484\n"
    }
   ],
   "source": [
    "epochs=120\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, callbacks=[cb_checkpoint,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1008 - val_accuracy: 0.5892\nEpoch 50/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7982 - accuracy: 0.6447\nEpoch 00050: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8042 - accuracy: 0.6425 - val_loss: 2.7856 - val_accuracy: 0.6430\nEpoch 51/120\n50/51 [============================>.] - ETA: 0s - loss: 2.9555 - accuracy: 0.6171\nEpoch 00051: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9557 - accuracy: 0.6150 - val_loss: 2.7691 - val_accuracy: 0.6577\nEpoch 52/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8153 - accuracy: 0.6385\nEpoch 00052: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.8160 - accuracy: 0.6394 - val_loss: 2.8840 - val_accuracy: 0.6455\nEpoch 53/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8146 - accuracy: 0.6550\nEpoch 00053: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8099 - accuracy: 0.6553 - val_loss: 2.7396 - val_accuracy: 0.6626\nEpoch 54/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8945 - accuracy: 0.6385\nEpoch 00054: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.8852 - accuracy: 0.6425 - val_loss: 3.2438 - val_accuracy: 0.5917\nEpoch 55/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9171 - accuracy: 0.6484\nEpoch 00055: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9227 - accuracy: 0.6455 - val_loss: 2.9242 - val_accuracy: 0.6650\nEpoch 56/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7907 - accuracy: 0.6714\nEpoch 00056: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.7887 - accuracy: 0.6705 - val_loss: 2.7467 - val_accuracy: 0.6455\nEpoch 57/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9003 - accuracy: 0.6490\nEpoch 00057: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.9018 - accuracy: 0.6486 - val_loss: 2.9043 - val_accuracy: 0.7090\nEpoch 58/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9241 - accuracy: 0.6528\nEpoch 00058: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9305 - accuracy: 0.6516 - val_loss: 2.8948 - val_accuracy: 0.6161\nEpoch 59/120\n50/51 [============================>.] - ETA: 0s - loss: 2.8122 - accuracy: 0.6559\nEpoch 00059: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8192 - accuracy: 0.6541 - val_loss: 3.1242 - val_accuracy: 0.6112\nEpoch 60/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9182 - accuracy: 0.6609\nEpoch 00060: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.9276 - accuracy: 0.6571 - val_loss: 3.1516 - val_accuracy: 0.5892\nEpoch 61/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8531 - accuracy: 0.6465\nEpoch 00061: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.8526 - accuracy: 0.6486 - val_loss: 2.9702 - val_accuracy: 0.6577\nEpoch 62/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8568 - accuracy: 0.6615\nEpoch 00062: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8535 - accuracy: 0.6638 - val_loss: 3.0185 - val_accuracy: 0.6504\nEpoch 63/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9506 - accuracy: 0.6422\nEpoch 00063: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9515 - accuracy: 0.6419 - val_loss: 3.0245 - val_accuracy: 0.6186\nEpoch 64/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7542 - accuracy: 0.6789\nEpoch 00064: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.7428 - accuracy: 0.6791 - val_loss: 3.0211 - val_accuracy: 0.5892\nEpoch 65/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8838 - accuracy: 0.6391\nEpoch 00065: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8844 - accuracy: 0.6400 - val_loss: 3.1671 - val_accuracy: 0.5917\nEpoch 66/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8108 - accuracy: 0.6714\nEpoch 00066: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8113 - accuracy: 0.6693 - val_loss: 2.9616 - val_accuracy: 0.6406\nEpoch 67/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9165 - accuracy: 0.6652\nEpoch 00067: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9179 - accuracy: 0.6644 - val_loss: 3.1803 - val_accuracy: 0.5599\nEpoch 68/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9058 - accuracy: 0.6665\nEpoch 00068: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9076 - accuracy: 0.6638 - val_loss: 2.9200 - val_accuracy: 0.6479\nEpoch 69/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7950 - accuracy: 0.6870\nEpoch 00069: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.7995 - accuracy: 0.6858 - val_loss: 3.0737 - val_accuracy: 0.6308\nEpoch 70/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9883 - accuracy: 0.6559\nEpoch 00070: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9855 - accuracy: 0.6589 - val_loss: 3.4642 - val_accuracy: 0.5941\nEpoch 71/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8511 - accuracy: 0.6745\nEpoch 00071: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8550 - accuracy: 0.6730 - val_loss: 2.9590 - val_accuracy: 0.6284\nEpoch 72/120\n50/51 [============================>.] - ETA: 0s - loss: 2.8611 - accuracy: 0.6863\nEpoch 00072: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8570 - accuracy: 0.6864 - val_loss: 3.3677 - val_accuracy: 0.5330\nEpoch 73/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8825 - accuracy: 0.6733\nEpoch 00073: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8803 - accuracy: 0.6742 - val_loss: 3.0730 - val_accuracy: 0.6137\nEpoch 74/120\n51/51 [============================>.] - ETA: 0s - loss: 2.9058 - accuracy: 0.6808\nEpoch 00074: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.9093 - accuracy: 0.6803 - val_loss: 3.4762 - val_accuracy: 0.5086\nEpoch 75/120\n50/51 [============================>.] - ETA: 0s - loss: 2.6933 - accuracy: 0.6946\nEpoch 00075: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.6846 - accuracy: 0.6968 - val_loss: 2.8384 - val_accuracy: 0.6039\nEpoch 76/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7363 - accuracy: 0.6708\nEpoch 00076: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.7397 - accuracy: 0.6711 - val_loss: 3.1218 - val_accuracy: 0.5990\nEpoch 77/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8809 - accuracy: 0.6901\nEpoch 00077: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8866 - accuracy: 0.6882 - val_loss: 3.1465 - val_accuracy: 0.5770\nEpoch 78/120\n51/51 [============================>.] - ETA: 0s - loss: 2.8288 - accuracy: 0.6914\nEpoch 00078: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.8264 - accuracy: 0.6925 - val_loss: 2.9946 - val_accuracy: 0.6210\nEpoch 79/120\n51/51 [============================>.] - ETA: 0s - loss: 2.7846 - accuracy: 0.6833\nEpoch 00079: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.7872 - accuracy: 0.6815 - val_loss: 2.9187 - val_accuracy: 0.6039\nEpoch 80/120\n51/51 [============================>.] - ETA: 0s - loss: 2.6630 - accuracy: 0.6895\nEpoch 00080: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.6633 - accuracy: 0.6882 - val_loss: 2.7260 - val_accuracy: 0.6895\nEpoch 81/120\n51/51 [============================>.] - ETA: 0s - loss: 2.5251 - accuracy: 0.7150\nEpoch 00081: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 2.5205 - accuracy: 0.7169 - val_loss: 2.5188 - val_accuracy: 0.6675\nEpoch 82/120\n50/51 [============================>.] - ETA: 0s - loss: 2.2915 - accuracy: 0.7390\nEpoch 00082: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.2930 - accuracy: 0.7376 - val_loss: 2.3834 - val_accuracy: 0.6846\nEpoch 83/120\n51/51 [============================>.] - ETA: 0s - loss: 2.1223 - accuracy: 0.7430\nEpoch 00083: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 2.1226 - accuracy: 0.7437 - val_loss: 2.2289 - val_accuracy: 0.7042\nEpoch 84/120\n51/51 [============================>.] - ETA: 0s - loss: 1.9631 - accuracy: 0.7791\nEpoch 00084: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.9612 - accuracy: 0.7797 - val_loss: 2.1776 - val_accuracy: 0.6455\nEpoch 85/120\n51/51 [============================>.] - ETA: 0s - loss: 1.8155 - accuracy: 0.7772\nEpoch 00085: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.8145 - accuracy: 0.7773 - val_loss: 2.0980 - val_accuracy: 0.6430\nEpoch 86/120\n51/51 [============================>.] - ETA: 0s - loss: 1.7020 - accuracy: 0.7909\nEpoch 00086: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.6995 - accuracy: 0.7919 - val_loss: 1.9709 - val_accuracy: 0.6846\nEpoch 87/120\n51/51 [============================>.] - ETA: 0s - loss: 1.5829 - accuracy: 0.8071\nEpoch 00087: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 44ms/step - loss: 1.5788 - accuracy: 0.8090 - val_loss: 1.7976 - val_accuracy: 0.7311\nEpoch 88/120\n51/51 [============================>.] - ETA: 0s - loss: 1.4319 - accuracy: 0.8332\nEpoch 00088: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.4406 - accuracy: 0.8316 - val_loss: 1.6140 - val_accuracy: 0.7433\nEpoch 89/120\n51/51 [============================>.] - ETA: 0s - loss: 1.3484 - accuracy: 0.8463\nEpoch 00089: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.3458 - accuracy: 0.8469 - val_loss: 1.6010 - val_accuracy: 0.7384\nEpoch 90/120\n51/51 [============================>.] - ETA: 0s - loss: 1.2847 - accuracy: 0.8407\nEpoch 00090: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.2806 - accuracy: 0.8420 - val_loss: 1.5433 - val_accuracy: 0.7579\nEpoch 91/120\n51/51 [============================>.] - ETA: 0s - loss: 1.2080 - accuracy: 0.8513\nEpoch 00091: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.2089 - accuracy: 0.8517 - val_loss: 1.5404 - val_accuracy: 0.7384\nEpoch 92/120\n51/51 [============================>.] - ETA: 0s - loss: 1.1583 - accuracy: 0.8755\nEpoch 00092: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.1612 - accuracy: 0.8737 - val_loss: 1.4734 - val_accuracy: 0.7433\nEpoch 93/120\n51/51 [============================>.] - ETA: 0s - loss: 1.0829 - accuracy: 0.8762\nEpoch 00093: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.0821 - accuracy: 0.8761 - val_loss: 1.4798 - val_accuracy: 0.7090\nEpoch 94/120\n50/51 [============================>.] - ETA: 0s - loss: 1.0185 - accuracy: 0.8940\nEpoch 00094: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 1.0208 - accuracy: 0.8926 - val_loss: 1.3714 - val_accuracy: 0.7555\nEpoch 95/120\n51/51 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.8923\nEpoch 00095: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.9600 - accuracy: 0.8932 - val_loss: 1.3251 - val_accuracy: 0.7628\nEpoch 96/120\n51/51 [============================>.] - ETA: 0s - loss: 0.9219 - accuracy: 0.9054\nEpoch 00096: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.9203 - accuracy: 0.9048 - val_loss: 1.3617 - val_accuracy: 0.7506\nEpoch 97/120\n51/51 [============================>.] - ETA: 0s - loss: 0.9199 - accuracy: 0.8986\nEpoch 00097: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.9186 - accuracy: 0.8993 - val_loss: 1.3356 - val_accuracy: 0.7457\nEpoch 98/120\n51/51 [============================>.] - ETA: 0s - loss: 0.8771 - accuracy: 0.9054\nEpoch 00098: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.8752 - accuracy: 0.9067 - val_loss: 1.3206 - val_accuracy: 0.7335\nEpoch 99/120\n51/51 [============================>.] - ETA: 0s - loss: 0.8399 - accuracy: 0.9197\nEpoch 00099: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.8427 - accuracy: 0.9189 - val_loss: 1.2928 - val_accuracy: 0.7555\nEpoch 100/120\n51/51 [============================>.] - ETA: 0s - loss: 0.8421 - accuracy: 0.9091\nEpoch 00100: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.8409 - accuracy: 0.9097 - val_loss: 1.2857 - val_accuracy: 0.7628\nEpoch 101/120\n51/51 [============================>.] - ETA: 0s - loss: 0.8055 - accuracy: 0.9191\nEpoch 00101: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.8056 - accuracy: 0.9195 - val_loss: 1.2819 - val_accuracy: 0.7433\nEpoch 102/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7683 - accuracy: 0.9347\nEpoch 00102: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7696 - accuracy: 0.9329 - val_loss: 1.2651 - val_accuracy: 0.7531\nEpoch 103/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7778 - accuracy: 0.9253\nEpoch 00103: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7801 - accuracy: 0.9243 - val_loss: 1.2599 - val_accuracy: 0.7482\nEpoch 104/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7746 - accuracy: 0.9203\nEpoch 00104: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 46ms/step - loss: 0.7736 - accuracy: 0.9213 - val_loss: 1.2634 - val_accuracy: 0.7482\nEpoch 105/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7645 - accuracy: 0.9259\nEpoch 00105: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7678 - accuracy: 0.9231 - val_loss: 1.2401 - val_accuracy: 0.7677\nEpoch 106/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7326 - accuracy: 0.9347\nEpoch 00106: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7330 - accuracy: 0.9347 - val_loss: 1.2316 - val_accuracy: 0.7555\nEpoch 107/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7216 - accuracy: 0.9378\nEpoch 00107: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7208 - accuracy: 0.9384 - val_loss: 1.2240 - val_accuracy: 0.7579\nEpoch 108/120\n50/51 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.9340\nEpoch 00108: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7343 - accuracy: 0.9335 - val_loss: 1.2145 - val_accuracy: 0.7555\nEpoch 109/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.9359\nEpoch 00109: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7232 - accuracy: 0.9347 - val_loss: 1.2115 - val_accuracy: 0.7555\nEpoch 110/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7366 - accuracy: 0.9322\nEpoch 00110: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7368 - accuracy: 0.9317 - val_loss: 1.2122 - val_accuracy: 0.7604\nEpoch 111/120\n50/51 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.9302\nEpoch 00111: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7202 - accuracy: 0.9311 - val_loss: 1.2108 - val_accuracy: 0.7579\nEpoch 112/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7168 - accuracy: 0.9440\nEpoch 00112: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7151 - accuracy: 0.9445 - val_loss: 1.2109 - val_accuracy: 0.7579\nEpoch 113/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7134 - accuracy: 0.9297\nEpoch 00113: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7121 - accuracy: 0.9304 - val_loss: 1.2126 - val_accuracy: 0.7604\nEpoch 114/120\n51/51 [============================>.] - ETA: 0s - loss: 0.6905 - accuracy: 0.9421\nEpoch 00114: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.6911 - accuracy: 0.9408 - val_loss: 1.2135 - val_accuracy: 0.7555\nEpoch 115/120\n50/51 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.9365\nEpoch 00115: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 47ms/step - loss: 0.6904 - accuracy: 0.9390 - val_loss: 1.2106 - val_accuracy: 0.7555\nEpoch 116/120\n50/51 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.9441\nEpoch 00116: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.6925 - accuracy: 0.9426 - val_loss: 1.2067 - val_accuracy: 0.7604\nEpoch 117/120\n51/51 [============================>.] - ETA: 0s - loss: 0.6871 - accuracy: 0.9446\nEpoch 00117: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.6847 - accuracy: 0.9457 - val_loss: 1.2005 - val_accuracy: 0.7628\nEpoch 118/120\n51/51 [============================>.] - ETA: 0s - loss: 0.7109 - accuracy: 0.9378\nEpoch 00118: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.7081 - accuracy: 0.9384 - val_loss: 1.2004 - val_accuracy: 0.7604\nEpoch 119/120\n51/51 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.9465\nEpoch 00119: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.6791 - accuracy: 0.9469 - val_loss: 1.2010 - val_accuracy: 0.7604\nEpoch 120/120\n51/51 [============================>.] - ETA: 0s - loss: 0.6846 - accuracy: 0.9384\nEpoch 00120: val_accuracy did not improve from 0.86797\n52/51 [==============================] - 2s 45ms/step - loss: 0.6851 - accuracy: 0.9378 - val_loss: 1.2010 - val_accuracy: 0.7604\n"
    }
   ],
   "source": [
    "epochs=120\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(x_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(x_train) / 32,\n",
    "    validation_data=(x_val, y_val), \n",
    "    epochs = epochs,\n",
    "    callbacks=[cb_checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (http://matplotlib.org/) -->\r\n<svg height=\"481.07625pt\" version=\"1.1\" viewBox=\"0 0 493.32438 481.07625\" width=\"493.32438pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 481.07625 \r\nL 493.32438 481.07625 \r\nL 493.32438 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 457.198125 \r\nL 233.012216 457.198125 \r\nL 233.012216 22.318125 \r\nL 30.103125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m9935c7d480\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.326265\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-30\"/>\r\n      </defs>\r\n      <g transform=\"translate(36.145015 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.078957\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 25 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-35\"/>\r\n      </defs>\r\n      <g transform=\"translate(71.716457 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.831648\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(110.469148 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"155.584339\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 75 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-37\"/>\r\n      </defs>\r\n      <g transform=\"translate(149.221839 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.33703\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-31\"/>\r\n      </defs>\r\n      <g transform=\"translate(184.79328 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.089721\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 125 -->\r\n      <g transform=\"translate(223.545971 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0981499175\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0981499175\" y=\"389.819357\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.2 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-2e\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 393.618575)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0981499175\" y=\"302.885867\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-34\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 306.685086)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0981499175\" y=\"215.952377\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-36\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 219.751596)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0981499175\" y=\"129.018887\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-38\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 132.818106)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0981499175\" y=\"42.085398\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 45.884616)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p91021c2dc9)\" d=\"M 39.326265 286.602419 \r\nL 40.876373 172.565202 \r\nL 42.426481 150.022944 \r\nL 43.976588 147.636125 \r\nL 45.526696 146.84051 \r\nL 47.076804 139.149636 \r\nL 48.626911 137.028013 \r\nL 50.177019 117.402993 \r\nL 51.727127 112.894552 \r\nL 53.277234 119.524616 \r\nL 54.827342 110.242537 \r\nL 56.37745 125.624286 \r\nL 57.927557 105.999292 \r\nL 59.477665 113.955363 \r\nL 61.027773 109.446922 \r\nL 62.57788 104.938481 \r\nL 64.127988 94.860762 \r\nL 65.678095 98.83881 \r\nL 67.228203 112.894552 \r\nL 68.778311 94.860762 \r\nL 70.328418 94.065147 \r\nL 71.878526 97.24758 \r\nL 73.428634 96.982384 \r\nL 74.978741 94.330369 \r\nL 76.528849 105.203677 \r\nL 78.078957 117.933412 \r\nL 79.629064 91.678328 \r\nL 81.179172 102.551636 \r\nL 82.72928 100.695236 \r\nL 84.279387 104.142866 \r\nL 85.829495 90.617517 \r\nL 87.379603 95.656376 \r\nL 88.92971 99.104006 \r\nL 90.479818 81.600609 \r\nL 92.029925 94.065147 \r\nL 93.580033 91.413132 \r\nL 95.130141 81.600609 \r\nL 96.680248 82.66142 \r\nL 98.230356 93.004335 \r\nL 99.780464 86.639468 \r\nL 101.330571 85.048264 \r\nL 102.880679 79.21379 \r\nL 104.430787 93.269558 \r\nL 105.980894 83.191838 \r\nL 107.531002 78.683397 \r\nL 109.08111 93.004335 \r\nL 110.631217 82.926642 \r\nL 112.181325 83.457035 \r\nL 113.731433 77.887782 \r\nL 115.28154 84.25265 \r\nL 116.831648 77.622586 \r\nL 118.381755 77.622586 \r\nL 119.931863 83.457035 \r\nL 121.481971 70.462104 \r\nL 123.032078 76.296553 \r\nL 124.582186 74.440152 \r\nL 126.132294 78.948593 \r\nL 127.682401 76.296553 \r\nL 129.232509 71.522915 \r\nL 130.782617 70.462104 \r\nL 132.332724 72.053308 \r\nL 133.882832 69.931685 \r\nL 135.43294 76.561775 \r\nL 136.983047 80.80502 \r\nL 138.533155 70.7273 \r\nL 140.083263 80.539797 \r\nL 141.63337 63.566818 \r\nL 143.183478 70.7273 \r\nL 144.733585 88.761091 \r\nL 146.283693 64.627629 \r\nL 147.833801 60.384384 \r\nL 149.383908 69.401293 \r\nL 150.934016 68.340481 \r\nL 152.484124 68.605678 \r\nL 154.034231 69.136096 \r\nL 155.584339 58.527984 \r\nL 157.134447 78.948593 \r\nL 158.684554 69.401293 \r\nL 160.234662 67.810063 \r\nL 161.78477 67.27967 \r\nL 163.334877 65.953663 \r\nL 164.884985 60.384384 \r\nL 166.435092 50.306691 \r\nL 167.9852 56.14114 \r\nL 169.535308 47.65465 \r\nL 171.085415 42.615816 \r\nL 172.635523 42.881013 \r\nL 174.185631 44.20702 \r\nL 175.735738 44.20702 \r\nL 177.285846 42.881013 \r\nL 178.835954 42.350594 \r\nL 180.386061 42.350594 \r\nL 181.936169 42.085398 \r\nL 183.486277 44.472216 \r\nL 185.036384 43.411405 \r\nL 186.586492 42.350594 \r\nL 188.1366 42.350594 \r\nL 189.686707 42.085398 \r\nL 191.236815 42.085398 \r\nL 192.786922 42.085398 \r\nL 194.33703 42.085398 \r\nL 195.887138 42.350594 \r\nL 197.437245 42.085398 \r\nL 198.987353 42.085398 \r\nL 200.537461 42.085398 \r\nL 202.087568 42.085398 \r\nL 203.637676 42.350594 \r\nL 205.187784 42.085398 \r\nL 206.737891 42.085398 \r\nL 208.287999 42.085398 \r\nL 209.838107 42.085398 \r\nL 211.388214 42.085398 \r\nL 212.938322 42.085398 \r\nL 214.48843 42.085398 \r\nL 216.038537 42.085398 \r\nL 217.588645 42.350594 \r\nL 219.138752 42.350594 \r\nL 220.68886 42.085398 \r\nL 222.238968 42.085398 \r\nL 223.789075 42.085398 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p91021c2dc9)\" d=\"M 39.326265 322.653133 \r\nL 40.876373 437.430852 \r\nL 42.426481 436.368095 \r\nL 43.976588 404.485397 \r\nL 45.526696 419.36399 \r\nL 47.076804 349.222056 \r\nL 48.626911 380.041996 \r\nL 50.177019 349.222056 \r\nL 51.727127 282.268392 \r\nL 53.277234 267.389792 \r\nL 54.827342 273.766331 \r\nL 56.37745 199.373374 \r\nL 57.927557 169.616201 \r\nL 59.477665 183.432033 \r\nL 61.027773 162.176895 \r\nL 62.57788 192.996822 \r\nL 64.127988 160.051386 \r\nL 65.678095 173.867218 \r\nL 67.228203 138.796248 \r\nL 68.778311 162.176895 \r\nL 70.328418 195.122356 \r\nL 71.878526 148.361063 \r\nL 73.428634 149.423817 \r\nL 74.978741 167.490666 \r\nL 76.528849 139.859002 \r\nL 78.078957 138.796248 \r\nL 79.629064 173.867218 \r\nL 81.179172 137.733494 \r\nL 82.72928 153.674834 \r\nL 84.279387 141.984511 \r\nL 85.829495 150.486571 \r\nL 87.379603 156.863123 \r\nL 88.92971 154.737589 \r\nL 90.479818 143.047265 \r\nL 92.029925 138.796248 \r\nL 93.580033 166.427912 \r\nL 95.130141 156.863123 \r\nL 96.680248 224.879529 \r\nL 98.230356 135.607985 \r\nL 99.780464 136.670739 \r\nL 101.330571 172.804464 \r\nL 102.880679 141.984511 \r\nL 104.430787 128.168679 \r\nL 105.980894 167.490666 \r\nL 107.531002 198.310619 \r\nL 109.08111 144.110019 \r\nL 110.631217 162.176895 \r\nL 112.181325 134.545231 \r\nL 113.731433 141.984511 \r\nL 115.28154 147.298308 \r\nL 116.831648 140.921757 \r\nL 118.381755 151.549326 \r\nL 119.931863 146.235554 \r\nL 121.481971 145.1728 \r\nL 123.032078 137.733494 \r\nL 124.582186 155.800343 \r\nL 126.132294 187.68305 \r\nL 127.682401 138.796248 \r\nL 129.232509 147.298308 \r\nL 130.782617 140.921757 \r\nL 132.332724 166.427912 \r\nL 133.882832 139.859002 \r\nL 135.43294 145.1728 \r\nL 136.983047 139.859002 \r\nL 138.533155 134.545231 \r\nL 140.083263 163.239649 \r\nL 141.63337 153.674834 \r\nL 143.183478 175.992727 \r\nL 144.733585 129.231433 \r\nL 146.283693 130.294187 \r\nL 147.833801 177.055481 \r\nL 149.383908 152.61208 \r\nL 150.934016 151.549326 \r\nL 152.484124 170.678955 \r\nL 154.034231 153.674834 \r\nL 155.584339 162.176895 \r\nL 157.134447 143.047265 \r\nL 158.684554 140.921757 \r\nL 160.234662 127.105924 \r\nL 161.78477 135.607985 \r\nL 163.334877 152.61208 \r\nL 164.884985 136.670739 \r\nL 166.435092 134.545231 \r\nL 167.9852 148.361063 \r\nL 169.535308 130.294187 \r\nL 171.085415 129.231433 \r\nL 172.635523 126.04317 \r\nL 174.185631 129.231433 \r\nL 175.735738 126.04317 \r\nL 177.285846 128.168679 \r\nL 178.835954 118.603864 \r\nL 180.386061 118.603864 \r\nL 181.936169 113.290092 \r\nL 183.486277 127.105924 \r\nL 185.036384 123.917662 \r\nL 186.586492 128.168679 \r\nL 188.1366 126.04317 \r\nL 189.686707 119.666618 \r\nL 191.236815 116.478355 \r\nL 192.786922 118.603864 \r\nL 194.33703 114.352847 \r\nL 195.887138 112.227338 \r\nL 197.437245 116.478355 \r\nL 198.987353 113.290092 \r\nL 200.537461 114.352847 \r\nL 202.087568 116.478355 \r\nL 203.637676 115.415601 \r\nL 205.187784 112.227338 \r\nL 206.737891 112.227338 \r\nL 208.287999 111.164584 \r\nL 209.838107 111.164584 \r\nL 211.388214 111.164584 \r\nL 212.938322 113.290092 \r\nL 214.48843 111.164584 \r\nL 216.038537 112.227338 \r\nL 217.588645 111.164584 \r\nL 219.138752 111.164584 \r\nL 220.68886 112.227338 \r\nL 222.238968 112.227338 \r\nL 223.789075 112.227338 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 457.198125 \r\nL 30.103125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 233.012216 457.198125 \r\nL 233.012216 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 457.198125 \r\nL 233.012216 457.198125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 22.318125 \r\nL 233.012216 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_12\">\r\n    <!-- Training and Validation Accuracy -->\r\n    <defs>\r\n     <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n     <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-72\"/>\r\n     <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-61\"/>\r\n     <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n     <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-6e\"/>\r\n     <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n     <path id=\"DejaVuSans-20\"/>\r\n     <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-64\"/>\r\n     <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n     <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-6c\"/>\r\n     <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-74\"/>\r\n     <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-6f\"/>\r\n     <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-41\"/>\r\n     <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-63\"/>\r\n     <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-75\"/>\r\n     <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-79\"/>\r\n    </defs>\r\n    <g transform=\"translate(32.420795 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-54\"/>\r\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-72\"/>\r\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"502.125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"565.503906\" xlink:href=\"#DejaVuSans-64\"/>\r\n     <use x=\"628.980469\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"660.767578\" xlink:href=\"#DejaVuSans-56\"/>\r\n     <use x=\"729.066406\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"790.345703\" xlink:href=\"#DejaVuSans-6c\"/>\r\n     <use x=\"818.128906\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"845.912109\" xlink:href=\"#DejaVuSans-64\"/>\r\n     <use x=\"909.388672\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"970.667969\" xlink:href=\"#DejaVuSans-74\"/>\r\n     <use x=\"1009.876953\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"1037.660156\" xlink:href=\"#DejaVuSans-6f\"/>\r\n     <use x=\"1098.841797\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"1162.220703\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"1194.007812\" xlink:href=\"#DejaVuSans-41\"/>\r\n     <use x=\"1262.400391\" xlink:href=\"#DejaVuSans-63\"/>\r\n     <use x=\"1317.380859\" xlink:href=\"#DejaVuSans-63\"/>\r\n     <use x=\"1372.361328\" xlink:href=\"#DejaVuSans-75\"/>\r\n     <use x=\"1435.740234\" xlink:href=\"#DejaVuSans-72\"/>\r\n     <use x=\"1476.853516\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"1538.132812\" xlink:href=\"#DejaVuSans-63\"/>\r\n     <use x=\"1593.113281\" xlink:href=\"#DejaVuSans-79\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 94.859091 452.198125 \r\nL 226.012216 452.198125 \r\nQ 228.012216 452.198125 228.012216 450.198125 \r\nL 228.012216 421.841875 \r\nQ 228.012216 419.841875 226.012216 419.841875 \r\nL 94.859091 419.841875 \r\nQ 92.859091 419.841875 92.859091 421.841875 \r\nL 92.859091 450.198125 \r\nQ 92.859091 452.198125 94.859091 452.198125 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_14\">\r\n     <path d=\"M 96.859091 427.940312 \r\nL 116.859091 427.940312 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\"/>\r\n    <g id=\"text_13\">\r\n     <!-- Training Accuracy -->\r\n     <g transform=\"translate(124.859091 431.440312)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-54\"/>\r\n      <use x=\"60.865234\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"101.978516\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"163.257812\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"191.041016\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"254.419922\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"282.203125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"345.582031\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"409.058594\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"440.845703\" xlink:href=\"#DejaVuSans-41\"/>\r\n      <use x=\"509.238281\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"564.21875\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"619.199219\" xlink:href=\"#DejaVuSans-75\"/>\r\n      <use x=\"682.578125\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"723.691406\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"784.970703\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"839.951172\" xlink:href=\"#DejaVuSans-79\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 96.859091 442.618437 \r\nL 116.859091 442.618437 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_14\">\r\n     <!-- Validation Accuracy -->\r\n     <g transform=\"translate(124.859091 446.118437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-56\"/>\r\n      <use x=\"68.298828\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"129.578125\" xlink:href=\"#DejaVuSans-6c\"/>\r\n      <use x=\"157.361328\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"185.144531\" xlink:href=\"#DejaVuSans-64\"/>\r\n      <use x=\"248.621094\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"309.900391\" xlink:href=\"#DejaVuSans-74\"/>\r\n      <use x=\"349.109375\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"376.892578\" xlink:href=\"#DejaVuSans-6f\"/>\r\n      <use x=\"438.074219\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"501.453125\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"533.240234\" xlink:href=\"#DejaVuSans-41\"/>\r\n      <use x=\"601.632812\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"656.613281\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"711.59375\" xlink:href=\"#DejaVuSans-75\"/>\r\n      <use x=\"774.972656\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"816.085938\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"877.365234\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"932.345703\" xlink:href=\"#DejaVuSans-79\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 273.594034 457.198125 \r\nL 476.503125 457.198125 \r\nL 476.503125 22.318125 \r\nL 273.594034 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"282.817175\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(279.635925 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"321.569866\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(315.207366 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"360.322557\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(353.960057 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"399.075248\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 75 -->\r\n      <g transform=\"translate(392.712748 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"437.827939\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(428.284189 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"476.58063\" xlink:href=\"#m9935c7d480\" y=\"457.198125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 125 -->\r\n      <g transform=\"translate(467.03688 471.796562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"439.041329\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(260.231534 442.840548)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"373.961461\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(260.231534 377.760679)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"308.881592\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(253.869034 312.68081)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"243.801723\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_24\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(253.869034 247.600942)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"178.721854\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_25\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(253.869034 182.521073)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"113.641985\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_26\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(253.869034 117.441204)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"273.594034\" xlink:href=\"#m0981499175\" y=\"48.562116\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_27\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-33\"/>\r\n      </defs>\r\n      <g transform=\"translate(253.869034 52.361335)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_31\">\r\n    <path clip-path=\"url(#pc7ba01781b)\" d=\"M 282.817175 42.085398 \r\nL 284.367282 195.056005 \r\nL 285.91739 288.027297 \r\nL 287.467498 333.237229 \r\nL 289.017605 354.498608 \r\nL 290.567713 368.452733 \r\nL 292.11782 379.582614 \r\nL 293.667928 389.668156 \r\nL 295.218036 399.517511 \r\nL 296.768143 401.438397 \r\nL 298.318251 406.835957 \r\nL 299.868359 401.620638 \r\nL 301.418466 409.68029 \r\nL 302.968574 408.015834 \r\nL 304.518682 409.147597 \r\nL 306.068789 412.40528 \r\nL 307.618897 414.577119 \r\nL 309.169005 416.066689 \r\nL 310.719112 408.644344 \r\nL 312.26922 413.299878 \r\nL 313.819328 417.714468 \r\nL 315.369435 415.622059 \r\nL 316.919543 414.65821 \r\nL 318.46965 417.675044 \r\nL 320.019758 409.435333 \r\nL 321.569866 404.849415 \r\nL 323.119973 414.640994 \r\nL 324.670081 413.142756 \r\nL 326.220189 411.072349 \r\nL 327.770296 409.773936 \r\nL 329.320404 415.826426 \r\nL 330.870512 412.994967 \r\nL 332.420619 410.889286 \r\nL 333.970727 418.50994 \r\nL 335.520835 416.403427 \r\nL 337.070942 415.683627 \r\nL 338.62105 417.148951 \r\nL 340.171158 419.865917 \r\nL 341.721265 412.755162 \r\nL 343.271373 413.786805 \r\nL 344.82148 415.854761 \r\nL 346.371588 416.649785 \r\nL 347.921696 412.459471 \r\nL 349.471803 414.134262 \r\nL 351.021911 419.373561 \r\nL 352.572019 413.484674 \r\nL 354.122126 414.919393 \r\nL 355.672234 413.610596 \r\nL 357.222342 419.928511 \r\nL 358.772449 415.819406 \r\nL 360.322557 416.27024 \r\nL 361.872665 416.819094 \r\nL 363.422772 415.377257 \r\nL 364.97288 420.678244 \r\nL 366.522987 418.634874 \r\nL 368.073095 420.87747 \r\nL 369.623203 415.911379 \r\nL 371.17331 417.650931 \r\nL 372.723418 421.225475 \r\nL 374.273526 422.431972 \r\nL 375.823633 421.282716 \r\nL 377.373741 422.556437 \r\nL 378.923849 419.661931 \r\nL 380.473956 418.072146 \r\nL 382.024064 420.716846 \r\nL 383.574172 414.714604 \r\nL 385.124279 423.158483 \r\nL 386.674387 423.11386 \r\nL 388.224495 411.510634 \r\nL 389.774602 419.09858 \r\nL 391.32471 424.068261 \r\nL 392.874817 420.323933 \r\nL 394.424925 421.613491 \r\nL 395.975033 422.773715 \r\nL 397.52514 421.91014 \r\nL 399.075248 425.04563 \r\nL 400.625356 415.598527 \r\nL 402.175463 419.806623 \r\nL 403.725571 421.177613 \r\nL 405.275679 421.50119 \r\nL 406.825786 421.997275 \r\nL 408.375894 422.643185 \r\nL 409.926002 428.041846 \r\nL 411.476109 426.134633 \r\nL 413.026217 430.264593 \r\nL 414.576325 433.136338 \r\nL 416.126432 434.481214 \r\nL 417.67654 434.948546 \r\nL 419.226647 435.148179 \r\nL 420.776755 435.586755 \r\nL 422.326863 436.016591 \r\nL 423.87697 436.395641 \r\nL 425.427078 436.655898 \r\nL 426.977186 436.292638 \r\nL 428.527293 436.43791 \r\nL 430.077401 436.62182 \r\nL 431.627509 436.73987 \r\nL 433.177616 436.906193 \r\nL 434.727724 437.011034 \r\nL 436.277832 437.10541 \r\nL 437.827939 437.166699 \r\nL 439.378047 437.209412 \r\nL 440.928155 437.243457 \r\nL 442.478262 437.272559 \r\nL 444.02837 437.304686 \r\nL 445.578477 437.327914 \r\nL 447.128585 437.327912 \r\nL 448.678693 437.348167 \r\nL 450.2288 437.363861 \r\nL 451.778908 437.373461 \r\nL 453.329016 437.380657 \r\nL 454.879123 437.396221 \r\nL 456.429231 437.402554 \r\nL 457.979339 437.406409 \r\nL 459.529446 437.412939 \r\nL 461.079554 437.398704 \r\nL 462.629662 437.401635 \r\nL 464.179769 437.422935 \r\nL 465.729877 437.428797 \r\nL 467.279985 437.430852 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_32\">\r\n    <path clip-path=\"url(#pc7ba01781b)\" d=\"M 282.817175 99.119487 \r\nL 284.367282 181.999089 \r\nL 285.91739 198.25565 \r\nL 287.467498 272.091101 \r\nL 289.017605 271.993984 \r\nL 290.567713 328.781523 \r\nL 292.11782 326.693946 \r\nL 293.667928 351.926322 \r\nL 295.218036 380.124509 \r\nL 296.768143 383.797463 \r\nL 298.318251 382.235883 \r\nL 299.868359 396.461771 \r\nL 301.418466 406.558838 \r\nL 302.968574 397.16295 \r\nL 304.518682 405.931671 \r\nL 306.068789 405.209097 \r\nL 307.618897 409.875132 \r\nL 309.169005 408.903203 \r\nL 310.719112 405.382238 \r\nL 312.26922 408.323313 \r\nL 313.819328 407.455782 \r\nL 315.369435 408.491704 \r\nL 316.919543 411.142129 \r\nL 318.46965 406.859547 \r\nL 320.019758 406.341327 \r\nL 321.569866 403.442553 \r\nL 323.119973 409.046606 \r\nL 324.670081 410.804745 \r\nL 326.220189 409.020171 \r\nL 327.770296 407.0125 \r\nL 329.320404 413.129899 \r\nL 330.870512 408.059526 \r\nL 332.420619 408.934913 \r\nL 333.970727 412.553687 \r\nL 335.520835 410.576453 \r\nL 337.070942 408.339933 \r\nL 338.62105 411.744769 \r\nL 340.171158 405.751116 \r\nL 341.721265 407.966093 \r\nL 343.271373 411.549369 \r\nL 344.82148 408.458411 \r\nL 346.371588 413.318927 \r\nL 347.921696 407.922314 \r\nL 349.471803 409.02406 \r\nL 351.021911 407.554925 \r\nL 352.572019 409.040075 \r\nL 354.122126 407.757058 \r\nL 355.672234 410.148273 \r\nL 357.222342 413.43198 \r\nL 358.772449 411.057756 \r\nL 360.322557 411.800886 \r\nL 361.872665 408.539008 \r\nL 363.422772 408.855696 \r\nL 364.97288 413.707765 \r\nL 366.522987 411.784046 \r\nL 368.073095 411.212691 \r\nL 369.623203 402.171369 \r\nL 371.17331 412.061188 \r\nL 372.723418 411.984387 \r\nL 374.273526 414.657575 \r\nL 375.823633 409.943548 \r\nL 377.373741 416.836845 \r\nL 378.923849 410.540686 \r\nL 380.473956 408.653581 \r\nL 382.024064 413.016513 \r\nL 383.574172 407.940154 \r\nL 385.124279 415.200129 \r\nL 386.674387 410.499805 \r\nL 388.224495 406.834096 \r\nL 389.774602 415.338751 \r\nL 391.32471 411.754077 \r\nL 392.874817 410.623298 \r\nL 394.424925 412.34449 \r\nL 395.975033 406.87536 \r\nL 397.52514 411.971852 \r\nL 399.075248 416.895511 \r\nL 400.625356 407.344093 \r\nL 402.175463 411.812099 \r\nL 403.725571 415.166788 \r\nL 405.275679 415.468498 \r\nL 406.825786 414.27182 \r\nL 408.375894 416.427874 \r\nL 409.926002 421.851818 \r\nL 411.476109 419.420875 \r\nL 413.026217 423.892293 \r\nL 414.576325 426.581573 \r\nL 416.126432 427.309884 \r\nL 417.67654 426.924121 \r\nL 419.226647 427.497114 \r\nL 420.776755 428.405571 \r\nL 422.326863 429.477748 \r\nL 423.87697 430.097687 \r\nL 425.427078 430.107828 \r\nL 426.977186 428.773797 \r\nL 428.527293 428.912976 \r\nL 430.077401 429.102873 \r\nL 431.627509 429.431106 \r\nL 433.177616 429.887688 \r\nL 434.727724 430.129828 \r\nL 436.277832 430.240229 \r\nL 437.827939 430.324366 \r\nL 439.378047 430.382184 \r\nL 440.928155 430.112091 \r\nL 442.478262 430.167611 \r\nL 444.02837 430.221998 \r\nL 445.578477 430.167781 \r\nL 447.128585 430.217596 \r\nL 448.678693 430.038691 \r\nL 450.2288 430.094343 \r\nL 451.778908 430.166695 \r\nL 453.329016 430.221454 \r\nL 454.879123 430.222469 \r\nL 456.429231 430.239351 \r\nL 457.979339 430.242342 \r\nL 459.529446 430.236873 \r\nL 461.079554 430.23534 \r\nL 462.629662 430.325093 \r\nL 464.179769 430.305466 \r\nL 465.729877 430.280924 \r\nL 467.279985 430.296803 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 273.594034 457.198125 \r\nL 273.594034 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 476.503125 457.198125 \r\nL 476.503125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 273.594034 457.198125 \r\nL 476.503125 457.198125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 273.594034 22.318125 \r\nL 476.503125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_28\">\r\n    <!-- Training and Validation Loss -->\r\n    <defs>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-4c\"/>\r\n     <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n    </defs>\r\n    <g transform=\"translate(290.14483 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-54\"/>\r\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-72\"/>\r\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"502.125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"565.503906\" xlink:href=\"#DejaVuSans-64\"/>\r\n     <use x=\"628.980469\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"660.767578\" xlink:href=\"#DejaVuSans-56\"/>\r\n     <use x=\"729.066406\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"790.345703\" xlink:href=\"#DejaVuSans-6c\"/>\r\n     <use x=\"818.128906\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"845.912109\" xlink:href=\"#DejaVuSans-64\"/>\r\n     <use x=\"909.388672\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"970.667969\" xlink:href=\"#DejaVuSans-74\"/>\r\n     <use x=\"1009.876953\" xlink:href=\"#DejaVuSans-69\"/>\r\n     <use x=\"1037.660156\" xlink:href=\"#DejaVuSans-6f\"/>\r\n     <use x=\"1098.841797\" xlink:href=\"#DejaVuSans-6e\"/>\r\n     <use x=\"1162.220703\" xlink:href=\"#DejaVuSans-20\"/>\r\n     <use x=\"1194.007812\" xlink:href=\"#DejaVuSans-4c\"/>\r\n     <use x=\"1249.705078\" xlink:href=\"#DejaVuSans-6f\"/>\r\n     <use x=\"1310.886719\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"1362.986328\" xlink:href=\"#DejaVuSans-73\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_2\">\r\n    <g id=\"patch_13\">\r\n     <path d=\"M 362.071875 59.674375 \r\nL 469.503125 59.674375 \r\nQ 471.503125 59.674375 471.503125 57.674375 \r\nL 471.503125 29.318125 \r\nQ 471.503125 27.318125 469.503125 27.318125 \r\nL 362.071875 27.318125 \r\nQ 360.071875 27.318125 360.071875 29.318125 \r\nL 360.071875 57.674375 \r\nQ 360.071875 59.674375 362.071875 59.674375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_33\">\r\n     <path d=\"M 364.071875 35.416562 \r\nL 384.071875 35.416562 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_34\"/>\r\n    <g id=\"text_29\">\r\n     <!-- Training Loss -->\r\n     <g transform=\"translate(392.071875 38.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-54\"/>\r\n      <use x=\"60.865234\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"101.978516\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"163.257812\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"191.041016\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"254.419922\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"282.203125\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"345.582031\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"409.058594\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"440.845703\" xlink:href=\"#DejaVuSans-4c\"/>\r\n      <use x=\"496.542969\" xlink:href=\"#DejaVuSans-6f\"/>\r\n      <use x=\"557.724609\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"609.824219\" xlink:href=\"#DejaVuSans-73\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_35\">\r\n     <path d=\"M 364.071875 50.094687 \r\nL 384.071875 50.094687 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_36\"/>\r\n    <g id=\"text_30\">\r\n     <!-- Validation Loss -->\r\n     <g transform=\"translate(392.071875 53.594687)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-56\"/>\r\n      <use x=\"68.298828\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"129.578125\" xlink:href=\"#DejaVuSans-6c\"/>\r\n      <use x=\"157.361328\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"185.144531\" xlink:href=\"#DejaVuSans-64\"/>\r\n      <use x=\"248.621094\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"309.900391\" xlink:href=\"#DejaVuSans-74\"/>\r\n      <use x=\"349.109375\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"376.892578\" xlink:href=\"#DejaVuSans-6f\"/>\r\n      <use x=\"438.074219\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"501.453125\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"533.240234\" xlink:href=\"#DejaVuSans-4c\"/>\r\n      <use x=\"588.9375\" xlink:href=\"#DejaVuSans-6f\"/>\r\n      <use x=\"650.119141\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"702.21875\" xlink:href=\"#DejaVuSans-73\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p91021c2dc9\">\r\n   <rect height=\"434.88\" width=\"202.909091\" x=\"30.103125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pc7ba01781b\">\r\n   <rect height=\"434.88\" width=\"202.909091\" x=\"273.594034\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./model/ScaleUpDatagenNormalfit06-0.8680-0.7251.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     id  digit\n0  2049      6\n1  2050      8\n2  2051      8\n3  2052      0\n4  2053      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2049</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2050</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2051</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2052</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2053</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "\n",
    "x_test = np.delete(x_test, (0), axis=1)\n",
    "x_test = np.delete(x_test, (-1), axis=1)\n",
    "x_test = np.delete(x_test, (0), axis=2)\n",
    "x_test = np.delete(x_test, (-1), axis=2)\n",
    "\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = np.argmax(model.predict(x_test), axis=1)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('08291040(ScaleUpDatagenNormalfit06-0.8680-0.7251).csv', index=False)"
   ]
  }
 ]
}